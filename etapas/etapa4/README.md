# ‚ö° Etapa 4: Otimiza√ß√£o e Tuning de Hiperpar√¢metros

**Prazo de Entrega:** [Data ser√° informada pelo professor]
**Peso:** 25% da nota do projeto (2.5 pontos)
**Entreg√°veis:**
- `notebooks/04_Otimizacao.ipynb`
- Modelo final salvo
- Apresenta√ß√£o de 15 minutos

---

## üéØ Objetivos da Etapa

Ao final desta etapa, voc√™ deve:

1. **Otimizar hiperpar√¢metros** - Tuning do melhor modelo da Etapa 3
2. **Evitar overfitting** - T√©cnicas de regulariza√ß√£o e valida√ß√£o
3. **Avaliar no conjunto de teste** - Desempenho final do modelo
4. **Salvar modelo final** - Modelo treinado pronto para produ√ß√£o

---

## üìã O Que Voc√™ Vai Entregar

### 1. Notebook Principal
**`notebooks/04_Otimizacao.ipynb`**

Se√ß√µes obrigat√≥rias:
1. Recapitula√ß√£o dos Resultados da Etapa 3
2. Sele√ß√£o do Modelo para Otimiza√ß√£o
3. Grid Search ou Random Search
4. An√°lise dos Melhores Hiperpar√¢metros
5. Treinamento do Modelo Final
6. Avalia√ß√£o no Conjunto de Teste
7. An√°lise de Erros Detalhada
8. Salvamento do Modelo
9. Conclus√µes Finais

### 2. Modelo Treinado
**`models/modelo_final.pkl`** (ou `.joblib`)
- Modelo otimizado e treinado
- Pronto para fazer predi√ß√µes

### 3. Apresenta√ß√£o (15 minutos) üé§

**O que apresentar:**
- Recapitula√ß√£o: melhor modelo da Etapa 3
- Processo de otimiza√ß√£o de hiperpar√¢metros
- Hiperpar√¢metros testados vs selecionados
- Compara√ß√£o: modelo antes vs depois da otimiza√ß√£o
- Desempenho final no conjunto de teste
- An√°lise de erros e limita√ß√µes
- Poss√≠veis melhorias futuras

**Formato:**
- 8-12 slides
- Todos os membros do grupo devem participar
- Inclua gr√°ficos de compara√ß√£o
- Mostre exemplos de predi√ß√µes

**Crit√©rios de avalia√ß√£o da apresenta√ß√£o:**
- Profundidade t√©cnica (35%)
- An√°lise cr√≠tica do modelo (25%)
- Visualiza√ß√µes e clareza (20%)
- Participa√ß√£o de todos (20%)

---

## üîç An√°lises Obrigat√≥rias

### 1. Otimiza√ß√£o de Hiperpar√¢metros

**Escolha uma t√©cnica:**

#### Op√ß√£o A: Grid Search (Busca Exaustiva)
Testa TODAS as combina√ß√µes de hiperpar√¢metros definidas.

**Pesquise:**
- Documenta√ß√£o do `sklearn.model_selection.GridSearchCV`
- Como definir um grid de hiperpar√¢metros
- Quais hiperpar√¢metros s√£o importantes para seu modelo
- Como usar cross-validation durante o tuning
- Como extrair os melhores par√¢metros

**Vantagens:** Garante encontrar a melhor combina√ß√£o no grid
**Desvantagens:** Pode ser muito lento

#### Op√ß√£o B: Random Search (Mais R√°pido)
Testa N combina√ß√µes ALEAT√ìRIAS de hiperpar√¢metros.

**Pesquise:**
- Documenta√ß√£o do `sklearn.model_selection.RandomizedSearchCV`
- Diferen√ßa entre Grid Search e Random Search
- Como definir distribui√ß√µes de hiperpar√¢metros
- Quantas itera√ß√µes (n_iter) usar
- Quando usar Random Search vs Grid Search

**Vantagens:** Muito mais r√°pido que Grid Search
**Desvantagens:** Pode n√£o encontrar a combina√ß√£o √≥tima

### 2. An√°lise dos Resultados do Tuning

**Objetivo:** Analisar os resultados do Grid/Random Search.

**Pesquise:**
- Atributo `.cv_results_` do GridSearchCV/RandomizedSearchCV
- Como converter resultados em DataFrame
- Como encontrar top N melhores combina√ß√µes
- Como visualizar compara√ß√£o entre configura√ß√µes
- Como criar gr√°fico de erro com barras de desvio padr√£o

### 3. Treinamento do Modelo Final

**Objetivo:** Treinar modelo final com melhores hiperpar√¢metros usando TREINO + VALIDA√á√ÉO.

**Pesquise:**
- Atributo `.best_estimator_` do GridSearchCV
- Atributo `.best_params_` para ver os par√¢metros escolhidos
- Como combinar conjuntos de treino e valida√ß√£o (pd.concat)
- Por que treinar no conjunto completo ap√≥s tuning

### 4. Avalia√ß√£o Final no Conjunto de Teste

**‚ö†Ô∏è IMPORTANTE:** S√≥ use o conjunto de teste UMA VEZ!

**Objetivo:** Avaliar desempenho final do modelo otimizado.

**Pesquise:**
- Como fazer predi√ß√µes no conjunto de teste
- Como calcular MAE, RMSE e R¬≤ (j√° viu na Etapa 3)
- Por que s√≥ podemos usar o teste uma vez
- Como formatar sa√≠da para apresenta√ß√£o clara

### 5. Compara√ß√£o: Antes vs Depois da Otimiza√ß√£o

**Objetivo:** Mostrar o impacto da otimiza√ß√£o.

**Pesquise:**
- Como criar DataFrame comparativo com pandas
- Como calcular melhoria percentual
- Como formatar tabela para apresenta√ß√£o
- Como interpretar se houve melhoria significativa

### 6. An√°lise de Erros Detalhada

**Gr√°ficos obrigat√≥rios:**

#### Scatter: Predito vs Real
**Pesquise:**
- Como criar scatter plot com linha diagonal de refer√™ncia
- Interpreta√ß√£o: pontos perto da linha = boas predi√ß√µes

#### Distribui√ß√£o dos Res√≠duos
**Pesquise:**
- Como criar subplots (1 linha, 2 colunas)
- Histograma de res√≠duos com linha vertical em x=0
- Scatter de res√≠duos vs predi√ß√µes com linha horizontal em y=0
- Como interpretar padr√µes nos res√≠duos

#### An√°lise de Casos Extremos
**Pesquise:**
- Como calcular erro absoluto
- Como encontrar N maiores valores (.nlargest)
- Como criar tabela mostrando piores predi√ß√µes
- Como interpretar por que o modelo errou nesses casos

### 7. Salvamento do Modelo

**Objetivo:** Salvar modelo final para uso futuro.

**Pesquise:**
- Biblioteca `joblib` para salvar modelos
- Como criar pasta se n√£o existir (`os.makedirs`)
- Diferen√ßa entre `.joblib` e `.pkl`
- Como carregar modelo salvo
- Como testar se o modelo carregado funciona corretamente

---

## ‚úÖ Crit√©rios de Avalia√ß√£o

| Crit√©rio | Peso | O Que Avaliamos |
|----------|:----:|-----------------|
| **Otimiza√ß√£o de Hiperpar√¢metros** | 30% | Grid/Random Search executado, melhores params identificados |
| **Avalia√ß√£o Final** | 25% | M√©tricas no teste, compara√ß√£o antes/depois |
| **An√°lise de Erros** | 20% | Res√≠duos, casos extremos, interpreta√ß√£o |
| **Documenta√ß√£o** | 10% | Markdown claro, decis√µes justificadas |
| **Apresenta√ß√£o** | 15% | Clareza, participa√ß√£o, profundidade t√©cnica |

---

## üì¶ Como Entregar

### 1. Commit e Push
```bash
# Criar pasta models
mkdir -p models

git add notebooks/04_Otimizacao.ipynb
git add models/modelo_final.joblib
git commit -m "feat: Completa Etapa 4 - Otimiza√ß√£o e modelo final"
git push origin main
```

### 2. Apresenta√ß√£o
- Upload dos slides em `docs/apresentacao_etapa4.pdf`
- Apresentar na aula marcada pelo professor

---

## üí° Dicas Importantes

**DO:**
‚úÖ Documente TODOS os hiperpar√¢metros testados
‚úÖ Use valida√ß√£o cruzada durante o tuning
‚úÖ Analise POR QUE o modelo erra (n√£o s√≥ QUANTO)
‚úÖ Compare antes vs depois da otimiza√ß√£o
‚úÖ Teste o modelo salvo para garantir que funciona

**DON'T:**
‚ùå Usar o conjunto de teste durante o tuning (data leakage!)
‚ùå Fazer tuning sem valida√ß√£o cruzada
‚ùå Testar hiperpar√¢metros aleatoriamente sem crit√©rio
‚ùå Esquecer de salvar o modelo final
‚ùå Ignorar an√°lise de erros

---

## üéØ Checklist Antes de Entregar

- [ ] Grid Search ou Random Search executado
- [ ] Melhores hiperpar√¢metros identificados
- [ ] Modelo final treinado com TREINO + VALIDA√á√ÉO
- [ ] Avalia√ß√£o no conjunto de TESTE (uma √∫nica vez)
- [ ] Compara√ß√£o antes vs depois criada
- [ ] An√°lise de res√≠duos completa
- [ ] Casos extremos (piores erros) analisados
- [ ] Modelo salvo em `models/modelo_final.joblib`
- [ ] Notebook executa "Restart & Run All" sem erros
- [ ] Apresenta√ß√£o preparada (8-12 slides)

---

## üÜò Precisa de Ajuda?

**D√∫vidas comuns:**
- Grid Search vs Random Search? ‚Üí Grid = exaustivo mas lento; Random = mais r√°pido
- Quantos hiperpar√¢metros testar? ‚Üí Comece com 3-4 principais
- Overfitting ap√≥s tuning? ‚Üí Verifique valida√ß√£o cruzada, pode precisar regulariza√ß√£o

**Consulte:**
- Scikit-learn hyperparameter tuning: https://scikit-learn.org/stable/modules/grid_search.html
- XGBoost tuning guide: https://xgboost.readthedocs.io/en/stable/tutorials/param_tuning.html
- Material da aula de otimiza√ß√£o

---

**√ìtima otimiza√ß√£o!** ‚ö°

*√öltima atualiza√ß√£o: Outubro 2027*
